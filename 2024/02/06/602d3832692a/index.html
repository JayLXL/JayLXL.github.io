<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>机器学习 | Jay and Erine's Blog</title><meta name="author" content="Jay and Erine"><meta name="copyright" content="Jay and Erine"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="FFF6E2"><meta name="description" content="K-Means方以类聚，物以群分。                    ——《易经》 聚类算法KMeans是无监督学习的杰出代表之一，K-Means可以做为其他聚类算法的基础。 基本思想通过迭代寻找K个簇（Cluster）的一种划分方案，使得聚类结果对应的损失函数最小。其中，损失函数可以定义为各个样本距离所属簇中心点的误差平方和： J(c, \mu)&#x3D;\sum_{i&#x3D;1}^{M}{||x_{i}">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习">
<meta property="og:url" content="https://jayerine.top/2024/02/06/602d3832692a/index.html">
<meta property="og:site_name" content="Jay and Erine&#39;s Blog">
<meta property="og:description" content="K-Means方以类聚，物以群分。                    ——《易经》 聚类算法KMeans是无监督学习的杰出代表之一，K-Means可以做为其他聚类算法的基础。 基本思想通过迭代寻找K个簇（Cluster）的一种划分方案，使得聚类结果对应的损失函数最小。其中，损失函数可以定义为各个样本距离所属簇中心点的误差平方和： J(c, \mu)&#x3D;\sum_{i&#x3D;1}^{M}{||x_{i}">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://blog-pics.obs.cn-north-4.myhuaweicloud.com/%E5%B0%81%E9%9D%A2/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%81%E9%9D%A2.jpg">
<meta property="article:published_time" content="2024-02-06T04:00:21.577Z">
<meta property="article:modified_time" content="2024-02-06T04:00:21.577Z">
<meta property="article:author" content="Jay and Erine">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog-pics.obs.cn-north-4.myhuaweicloud.com/%E5%B0%81%E9%9D%A2/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%81%E9%9D%A2.jpg"><link rel="shortcut icon" href="https://s1.ax1x.com/2023/03/01/ppieNl9.png"><link rel="canonical" href="https://jayerine.top/2024/02/06/602d3832692a/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/all","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-02-06 12:00:21'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/fish.css"><script src="/js/sakura.js"></script><link rel="stylesheet" href="/css/footer_trans.css"><link rel="stylesheet" href="/css/scrollbar.css"><link rel="stylesheet" href="/css/cursor.css"><link rel="stylesheet" href="/css/mathjax_display.css"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Jay and Erine's Blog" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s1.ax1x.com/2023/02/27/ppCAPEQ.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">36</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Jay and Erine's Blog"><span class="site-name">Jay and Erine's Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">机器学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-02-06T04:00:21.577Z" title="Created 2024-02-06 12:00:21">2024-02-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-02-06T04:00:21.577Z" title="Updated 2024-02-06 12:00:21">2024-02-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><h2 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/184686598">K-Means</a></h2><figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">方以类聚，物以群分。</span><br><span class="line">                    ——《易经》</span><br></pre></td></tr></table></figure>
<p>聚类算法KMeans是无监督学习的杰出代表之一，K-Means可以做为其他聚类算法的基础。</p>
<h3 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h3><p>通过迭代寻找K个簇（Cluster）的一种划分方案，使得聚类结果对应的损失函数最小。其中，损失函数可以定义为各个样本距离所属簇中心点的误差平方和：</p>
<script type="math/tex; mode=display">J(c, \mu)=\sum_{i=1}^{M}{||x_{i}-\mu_{c_{i}}||^{2}}</script><p>其中 $x_{i}$ 代表第 $i$ 个样本， $c_{i}$ 是 $x_{i}$ 所属的簇， $\mu_{c_{i}}$ 代表簇对应的中心点， $M$ 是样本总数。</p>
<h3 id="主要过程"><a href="#主要过程" class="headerlink" title="主要过程"></a>主要过程</h3><ol>
<li>选定初始簇中心</li>
<li>更新簇中心位置</li>
<li>更新分类归属</li>
<li>重复2、3步到簇中心不在变化</li>
</ol>
<h3 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h3><p>KMeans的核心目标是将给定的数据集划分成K个簇（K是超参），并给出每个样本数据对应的中心点。具体步骤非常简单，可以分为4步：</p>
<p>（1）数据预处理。主要是标准化、异常点过滤。</p>
<p>（2）随机选取K个中心，记为 $\mu_{1}^{(0)},\mu_{2}^{(0)},…,\mu_{k}^{(0)}$</p>
<p>（3）定义损失函数： $J(c, \mu)=min\sum_{i=1}^{M}{||x_{i}-\mu_{c_{i}}||^{2}}$</p>
<p>（4）令$t=0,1,2,…$ 为迭代步数，重复如下过程直到 J 收敛：</p>
<ul>
<li>对于每一个样本 $x_{i}$ ，将其分配到距离最近的中心</li>
</ul>
<script type="math/tex; mode=display">c_{i}^{t} <—argmin_{k}{||x_{i}-\mu_{k}^{t}||^{2}}</script><ul>
<li>对于每一个类中心k，重新计算该类的中心</li>
</ul>
<script type="math/tex; mode=display">\mu_{k}^{(t+1)} <—argmin_{\mu}\sum_{i:c_{i}^{t}=k}^{b}{||x_{i}-\mu||^{2}}</script><p>KMeans最核心的部分就是先固定中心点，调整每个样本所属的类别来减少 J ；再固定每个样本的类别，调整中心点继续减小J 。两个过程交替循环， J 单调递减直到最（极）小值，中心点和样本划分的类别同时收敛。</p>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>KMenas的优点：</p>
<ul>
<li>高效可伸缩，计算复杂度 为O(NKt)接近于线性（N是数据量，K是聚类总数，t是迭代轮数）。</li>
<li>收敛速度快，原理相对通俗易懂，可解释性强。</li>
</ul>
<p>KMeans也有一些明显的缺点：</p>
<ul>
<li>受初始值和异常点影响，聚类结果可能不是全局最优而是局部最优。</li>
<li>K是超参数，一般需要按经验选择。</li>
<li>样本点只能划分到单一的类中。</li>
<li>不适合圆形数据集的分类（非凸数据集）。<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3>图像压缩：图像矢量量化。<blockquote>
<p>对颜色进行聚类，若原图256*256，每个像素用24个比特的RGB表示。若经过聚类颜色之后剩下64种颜色，只用6比特表示颜色，压缩率为$\frac{6}{24}\times 100\%$。</p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3></blockquote>
</li>
</ul>
<ol>
<li><p>数据预处理：归一化和异常点过滤</p>
<p> KMeans本质上是一种基于欧式距离度量的数据划分方法，均值和方差大的维度将对数据的聚类结果产生决定性影响。所以在聚类前对数据（具体的说是每一个维度的特征）做归一化和单位统一至关重要。此外，异常值会对均值计算产生较大影响，导致中心偏移，这些噪声点最好能提前过滤。</p>
</li>
<li><p>合理选择K值</p>
<p> K值的选择一般基于实验和多次实验结果。例如采用手肘法，尝试不同K值并将对应的损失函数画成折线。手肘法认为图上的拐点就是K的最佳值。</p>
<p> 为了将找寻最佳K值的过程自动化，研究人员提出了Gap Statistic方法。它的有点是我们不再需要肉眼判断，只需要找到最大的Gap Statistic对应的K即可。</p>
<p> 沿用第一节中损失函数记为 $D_{k}$ ，当分为K类时，Gap Statistic定义为： $Gap(k)=E(logD_{k})-logD_{k}$ 。 $E(logD_{k})$ 是 $logD_{k}$ 的期望，一般由蒙特卡洛模拟产生。我们在样本所在的区域内按照均匀分布随机地产生和原始样本数一样多的随机样本，并对这个随机样本做KMeans，得到一个 $D_{k}$ ，重复多次就可以计算出 $E(logD_{k})$ 的近似值。</p>
<p> $Gap(K)$ 的物理含义是随机样本的损失与实际样本的损失之差。$Gap$越大说明聚类的效果越好。一种极端情况是，随着K的变化 $Gap(K)$ 几乎维持一条直线保持不变。说明这些样本间没有明显的类别关系，数据分布几乎和均匀分布一致，近似随机。此时做聚类没有意义。</p>
</li>
<li><p>改进初始值的选择</p>
<p> 之前我们采取随机选择K个中心的做法，可能导致不同的中心点距离很近，就需要更多的迭代次数才能收敛。如果在选择初始中心点时能让不同的中心尽可能远离，效果往往更好。这类算法中，以K-Means++算法最具影响力。</p>
</li>
<li><p>采用核函数</p>
<p> 主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的空间进行聚类。非线性映射增加了数据点线性可分的概率（与SVM中使用核函数思想类似）对于非凸的数据分布可以达到更为准确的聚类结果。</p>
</li>
</ol>
<h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/31886934">SVM</a></h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>支持向量机（support vector machines, SVM）是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机；SVM还包括核技巧，这使它成为实质上的非线性分类器。SVM的的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。SVM的的学习算法就是求解凸二次规划的最优化算法。属于有监督学习。</p>
<p>研究对线性二分类问题的凸优化问题的表示，以及支持向量机的求解。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>SVM学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面。如下图所示， $\boldsymbol{w}\cdot x+b=0$ 即为分离超平面，对于线性可分的数据集来说，这样的超平面有无穷多个（即感知机），但是几何间隔最大的分离超平面却是唯一的。<br><img src="https://blog-pics.obs.cn-north-4.myhuaweicloud.com/支持向量机.jpg" alt="二分类划分"></p>
<script type="math/tex; mode=display">w=[w1,w2]\quad x=[x,y]^T</script><p>点到超平面的距离是</p>
<script type="math/tex; mode=display">d=\frac{|xX_0+b|}{||w||}</script><p>若$X_0$为支持向量，</p>
<script type="math/tex; mode=display">d=\frac{1}{||w||}</script><p>用a缩放w和b，$(w,b)\rightarrow(aw,ab)$</p>
<p>当$|wx_0+b|=1$，$x_0$是支持向量。</p>
<p>当$|wx_0+b|&gt;1$，$x_0$非支持向量。</p>
<h3 id="支持向量机的求解"><a href="#支持向量机的求解" class="headerlink" title="支持向量机的求解"></a>支持向量机的求解</h3><p>支持向量机求解是一个凸问题，存在唯一一个全局极值。</p>
<p>凸问题总能找到高效快速的算法来解决。</p>
<ul>
<li>拉格朗日乘子法求解</li>
<li>用现成数学包求解<h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/30059442">决策树</a></h2>决策树是一种十分常用的分类方法，需要监管学习。<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3>熵：表示信息的不确定性，即混乱程度。<script type="math/tex; mode=display">H(D)=-\sum_{i=1}^N p_ilog_2p_i</script>$p_i$表示取到某个信息元素D的概率。</li>
</ul>
<p>信息增益：表示得知特征A的信息而使得类X得信息不确定性减少得程度。<br>若用g(D,A)表示特征A对训练数据集D得信息增益，则有：</p>
<script type="math/tex; mode=display">g(D,A)=H(D)-H(D|A)</script><p>D|A表示加入A特征之后的训练集D。</p>
<p>条件熵：假设在特征A上有m个分支节点，其中$D_i$表示特征A得第i个分支得节点的数据，则</p>
<script type="math/tex; mode=display">H(D|A)=\sum_{i=1}^m\frac{|D_i|}{|D|}H(D_i)</script><p>即，特征A的分支节点的熵的加权和。</p>
<h3 id="训练期望"><a href="#训练期望" class="headerlink" title="训练期望"></a>训练期望</h3><ul>
<li>希望随着树深度的增加，节点的熵迅速的降低。</li>
<li>得到一个高度最矮的决策树。</li>
<li>到叶子节点的熵值为0，此时叶子节点为纯节点，即每个叶子节点中的实例都属于同一类。<h3 id="决策树的构造"><a href="#决策树的构造" class="headerlink" title="决策树的构造"></a>决策树的构造</h3>计算所有属性的信息增益，选择当前信息增益最大的特征进行划分。<h3 id="改进算法"><a href="#改进算法" class="headerlink" title="改进算法"></a>改进算法</h3>CART算法。<h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2>卷积神经网络（Convolutional Neural Networks）是一种深度学习模型或类似于人工神经网络的多层感知器，常用来分析视觉图像。</li>
</ul>
<p>全连神经网络数量太庞大，不适合处理图像，因此需要通过CNN局部感知。<br>CNN特点：</p>
<ul>
<li>局部感知</li>
<li>参数共享</li>
<li>多卷积核</li>
<li><p>池化处理</p>
<p>最大池化、平均池化</p>
</li>
<li><p>多层结构</p>
<p>层数越多，学到的特征越全局化</p>
</li>
</ul>
<p>卷积计算，使用哈达玛积。</p>
<p>步长：滑动的长度</p>
<p>窄卷积和宽卷积：对图像边缘的处理，是否扩充图片边缘。</p>
<p>2023.3.18</p>
<h2 id="图像语义分割"><a href="#图像语义分割" class="headerlink" title="图像语义分割"></a>图像语义分割</h2><p>概念：对图像中的每个像素进行分类。</p>
<p>任务：识别图像中存在的内容及位置。</p>
<h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p>用$J(\theta_1)$表示$h_{\theta}(x)$的代价函数。</p>
<script type="math/tex; mode=display">J(\theta_1)=\frac{1}{2m}\sum(h_\theta(x^{(i)})-y^{(i)})^2</script><h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><script type="math/tex; mode=display">\theta_j=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1) \space\space(for\space j=0\space and\space j=1)</script><p>$\alpha$称为学习率，学习率太大，会导致发散，学习率太小，会导致收敛过慢。<br>如何找到合适的学习率？<br>画出$min\space J(\theta)-No.of\space iteration$图像，判断算法是否已经收敛，挥着通过自动收敛测试判断。如果函数递增，则说明没有收敛，需要使用较小的学习率。最开始的时候可以每隔十倍取一次值尝试。<br>convex function 凸函数<br>Feature Scaling：通过放缩特征数据的范围一致，使得梯度下降法运行效果更加丝滑。<br>Mean normalization（均值归一化）：通过平移和放缩，使得特征数据的样本中心接近。<br>可以通过简单的特征变换，拟合不同的函数。</p>
<h2 id="正规方程法"><a href="#正规方程法" class="headerlink" title="正规方程法"></a>正规方程法</h2><p>正规方程法求$\Theta$推导：<br>设样本特征数为n，样本个数为m，则设$X$为样本构成的$n\times m$的矩阵，$Y_{m\times 1}$为真实预测值，$\Theta_{n\times 1}$为待求参数值，则价值函数的矩阵形式为：</p>
<script type="math/tex; mode=display">J(\Theta)=(X\Theta -Y)^T(X\Theta -Y)</script><p>由微分知识可知，当任意的$\theta_i$满足</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial\theta_i}J(\Theta)=0</script><p>时，存在极值，于是对于每个$\theta_i$，求$J(\Theta)$的偏导等于0。化简，得到：</p>
<script type="math/tex; mode=display">J(\Theta)=\Theta^T X^TX\Theta-2Y^TX\Theta</script><p>考虑在$A_{1\times n}\Theta_{n\times 1}$中，对每一个$\theta_i$求导，得到极值条件：</p>
<script type="math/tex; mode=display">A^T=0</script><p>考虑在$\Theta_{n\times 1}^T A_{n\times n}\Theta_{n\times 1}$中，对每一个$\theta_i$求导，得到极值条件：</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial \theta_i}(\Theta_{n\times 1}^T A_{n\times n}\Theta_{n\times 1})=\frac{\partial}{\partial \theta_i}(\Theta^Ta_{xi}+a_{ix}\Theta-\theta_i^2aii)=2a_{ix}\theta_i</script><p>因此通过求导和重新排列，· 得到$J(\Theta)$的极值条件：</p>
<script type="math/tex; mode=display">2X^TX\Theta -2X^TY=0</script><p>即</p>
<script type="math/tex; mode=display">\Theta=(X^TX)^{-1}X^TY</script><p>线性代数中，可以通过正规方程法，直接求使得代价函数最小的$\Theta$，但是由于正规方程法是$O(n^3)$复杂度，在数据量很大时，只能使用梯度下降法。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://jayerine.top">Jay and Erine</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://jayerine.top/2024/02/06/602d3832692a/">https://jayerine.top/2024/02/06/602d3832692a/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post_share"><div class="social-share" data-image="https://blog-pics.obs.cn-north-4.myhuaweicloud.com/%E5%B0%81%E9%9D%A2/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%81%E9%9D%A2.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/02/06/19d418e9f6fa/" title="创新课程"><img class="cover" src="https://blog-pics.obs.cn-north-4.myhuaweicloud.com/%E5%B0%81%E9%9D%A2/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%81%E9%9D%A2.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">创新课程</div></div></a></div><div class="next-post pull-right"><a href="/2024/02/06/125b95e4ccef/" title="鲲鹏软件迁移"><img class="cover" src="https://s1.ax1x.com/2023/03/01/ppiUGb8.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next</div><div class="next_info">鲲鹏软件迁移</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2024/02/06/f554b43ffd79/" title="vscode配置opencv C++ 环境与人脸检测（不是人脸识别）算法的尝试"><img class="cover" src="https://s1.ax1x.com/2023/03/02/ppFFjVU.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-06</div><div class="title">vscode配置opencv C++ 环境与人脸检测（不是人脸识别）算法的尝试</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s1.ax1x.com/2023/02/27/ppCAPEQ.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Jay and Erine</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">36</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/JayLXL/BlogDevelopment"><i class="fab fa-github"></i><span>Github</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Jay and Erine are best friend.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#K-Means"><span class="toc-number">1.</span> <span class="toc-text">K-Means</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3"><span class="toc-number">1.1.</span> <span class="toc-text">基本思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E8%BF%87%E7%A8%8B"><span class="toc-number">1.2.</span> <span class="toc-text">主要过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E8%BF%87%E7%A8%8B"><span class="toc-number">1.3.</span> <span class="toc-text">具体过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.4.</span> <span class="toc-text">优缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8"><span class="toc-number">1.5.</span> <span class="toc-text">应用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96"><span class="toc-number">1.6.</span> <span class="toc-text">优化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SVM"><span class="toc-number">2.</span> <span class="toc-text">SVM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">2.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%9F%E7%90%86"><span class="toc-number">2.2.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E6%B1%82%E8%A7%A3"><span class="toc-number">2.3.</span> <span class="toc-text">支持向量机的求解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">3.</span> <span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5"><span class="toc-number">3.1.</span> <span class="toc-text">概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%9C%9F%E6%9C%9B"><span class="toc-number">3.2.</span> <span class="toc-text">训练期望</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E6%9E%84%E9%80%A0"><span class="toc-number">3.3.</span> <span class="toc-text">决策树的构造</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%B9%E8%BF%9B%E7%AE%97%E6%B3%95"><span class="toc-number">3.4.</span> <span class="toc-text">改进算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CNN"><span class="toc-number">4.</span> <span class="toc-text">CNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"><span class="toc-number">5.</span> <span class="toc-text">图像语义分割</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0"><span class="toc-number">6.</span> <span class="toc-text">代价函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="toc-number">7.</span> <span class="toc-text">梯度下降法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E6%B3%95"><span class="toc-number">8.</span> <span class="toc-text">正规方程法</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/02/06/137184bfb43a/" title="面试记录"><img src="https://blog-pics.obs.cn-north-4.myhuaweicloud.com/%E5%B0%81%E9%9D%A2/Jay%E7%AE%80%E5%8E%86%E5%B0%81%E9%9D%A2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="面试记录"/></a><div class="content"><a class="title" href="/2024/02/06/137184bfb43a/" title="面试记录">面试记录</a><time datetime="2024-02-06T04:00:21.577Z" title="Created 2024-02-06 12:00:21">2024-02-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/06/bb4263303c4c/" title="git使用"><img src="https://s1.ax1x.com/2023/03/10/ppnbMQ0.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="git使用"/></a><div class="content"><a class="title" href="/2024/02/06/bb4263303c4c/" title="git使用">git使用</a><time datetime="2024-02-06T04:00:21.577Z" title="Created 2024-02-06 12:00:21">2024-02-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/06/0e751f91670a/" title="两棵树（可持久线段树+Hash+高精度数）"><img src="https://s1.ax1x.com/2023/03/02/ppFFvaF.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="两棵树（可持久线段树+Hash+高精度数）"/></a><div class="content"><a class="title" href="/2024/02/06/0e751f91670a/" title="两棵树（可持久线段树+Hash+高精度数）">两棵树（可持久线段树+Hash+高精度数）</a><time datetime="2024-02-06T04:00:21.577Z" title="Created 2024-02-06 12:00:21">2024-02-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/06/f554b43ffd79/" title="vscode配置opencv C++ 环境与人脸检测（不是人脸识别）算法的尝试"><img src="https://s1.ax1x.com/2023/03/02/ppFFjVU.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="vscode配置opencv C++ 环境与人脸检测（不是人脸识别）算法的尝试"/></a><div class="content"><a class="title" href="/2024/02/06/f554b43ffd79/" title="vscode配置opencv C++ 环境与人脸检测（不是人脸识别）算法的尝试">vscode配置opencv C++ 环境与人脸检测（不是人脸识别）算法的尝试</a><time datetime="2024-02-06T04:00:21.577Z" title="Created 2024-02-06 12:00:21">2024-02-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/06/feae35703595/" title="奇怪名词解释"><img src="https://blog-pics.obs.cn-north-4.myhuaweicloud.com/%E5%B0%81%E9%9D%A2/%E5%A5%87%E6%80%AA%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E5%B0%81%E9%9D%A2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="奇怪名词解释"/></a><div class="content"><a class="title" href="/2024/02/06/feae35703595/" title="奇怪名词解释">奇怪名词解释</a><time datetime="2024-02-06T04:00:21.577Z" title="Created 2024-02-06 12:00:21">2024-02-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By Jay and Erine</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script><script src="https://gcore.jsdelivr.net/gh/xiabo2/CDN@latest/fishes.js"></script><script type="text/javascript" src="/js/fairyDustCursor.js"></script><script id="canvas_nest" defer="defer" color="255,240,245" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>